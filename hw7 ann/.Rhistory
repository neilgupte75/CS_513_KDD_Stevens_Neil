second
second<-avector["second"]
second
avector
names(avector)<-c("first","second","third","fourth")
second<-avector["second"]
second
second<-avector[2]
second
avector
avector[22]
avector[2]<-22
avector
my.lst<-list(stud.id=34445,stud.name=c("neil","asdads"),stud.marks=c(2,1,2))
my.lst[2]
typeof(my.lst[2])
my.lst2[[2]]
my.lst[[2]]
typeof(my.lst[[2]])
is.vector(my.lst[[2]])
element2<-my.lst[[2]]
ln<-my.lst[[2]][2]
ln
rm(ls)
rm(list=ls())
data()
data(iris)
View(iris)
iris[5,4]
iris[-3,]
iris[,-3]
iris[-3,]
iris[,-3]#everything except 3 column
iris[-3,] #everything except 3 row
iris[c(13,5,10),c(5,2,4)]
subset4<-iris[c(T,F,F,F),]
subset4
?sample
sample(100,60)
sample(160,60)
idx<-sample(nrow(iris),as.integer(.65*nrow(iris))
idx
idx<-sample(nrow(iris),as.integer(.65*nrow(iris)))
idx
training<-iris[idx,]
test<-iris[-idx,]
idx<-seq(1,nrow(iris),5)
idx
vec<-1:20
mnnorm(vec)
mnnorm<-function(x.minx,maxx)
{
z<-((x-minx)/(maxx-minx))
return(z)
}
mnnorm(vec)
mnnorm<-function(x,minx,maxx)
{
z<-((x-minx)/(maxx-minx))
return(z)
}
vec<-1:20
mnnorm(vec)
mnnorm(vec,1,20)
install.packages(c("kknn", "VIM"))
rm(list=ls())
data(iris)
View(iris)
length(iris)
nrow(iris)
iris_missing<-iris
iris_missing[c(3,30,40),3]<-NA
View(iris_missing)
View(iris_missing)
View(iris)
View(iris)
summary(iris_missing)
?boxplot()
boxplot(iris[1:3])  ### sepal width contains some outliers ###
?hist()
hist(iris$Sepal.Length)
?pairs()
pairs(iris[1:2])
pairs(iris[1:4])
pairs(iris[1:4], main="Iris Data", pch=10)
pairs(iris[1:4])
pairs(iris[1:4], main="Iris Data", pch=1)
pairs(iris[1:4], main="Iris Data", pch=20)
pairs(iris[1:4], main="Iris Data", pch=10)
pairs(iris[1:4], main="Anderson's Iris Data -- 3 species", pch=21, bg=c("red", "green3","blue")[factor(iris$species)])
pairs(iris[1:4], main="Anderson's Iris Data -- 3 species", pch=21, bg=c("red", "green3","blue")[factor(iris$Species)])
?plot()
?plot()
plot(iris[,1:2])
?na.omit
iris_missing<-na.omit(iris_missing)
x<-c(1,2,6,6,6,7,7,7)
unique.x<-unique(x)
?match()
match(x, unique.x) ### matches the elements in x with unique.x and gives the index of the matched position ###
?tabulate()
tab<-tabulate(match(x, unique.x)) ### tabulate: counts the repitition ###
unique.x[tab==max(tab)]
max(x)
max(unique.x)
max(tab)
mfv <- function(x) {
unique.x<-unique(x)
tab<-tabulate(match(x, unique.x))
unique.x[tab==max(tab)]
}
mfv.x<-mfv(x)
mfv.x<-mfv(x)
mfv.x               ### the most frequent value may not be unique ###
is.vector(mfv.x)
?sample()
library("kknn")
?kknn()
predict_k5<-kknn(formula=Species~.,training, test[,-5], k=5, kernel='rectangular')
index <- seq(1,nrow(iris),by=5)
index
test<-iris[index,]
training<-iris[-index,]
predict_k5<-kknn(formula=Species~.,training, test[,-5], k=5, kernel='rectangular')
predict_k5
fit<-fitted(predict_k5)
table(Actual=test$Species, fit)
iris_normalized<-as.data.frame (
cbind( Sepal.Length=mmnorm(iris[,1],min(iris[,1]),max(iris[,1]))
, sepal.Width=mmnorm(iris[,2],min(iris[,2]),max(iris[,2] ))
,Petal.Length=mmnorm(iris[,3],min(iris[,3]),max(iris[,3] ))
, Petal.Width=mmnorm(iris[,4],min(iris[,4]),max(iris[,4] ))
,Species=as.character(iris[,5])
)
)
###  rectangular: unweighted, default: Euclidian, k=5: picking the 5 nearest neighbours  ###
predict_k5<-kknn(formula=Species~.,training, test[,-5], k=5, kernel='rectangular')
predict_k5
predict_k5
table(Actual=test$Species, fit)
test<-iris_normalized[index,]
training <-iris_normalized[-index,]
predict_k5 <- kknn(formula=Species~., training, test[,-5], k=5,kernel ="triangular" )
fit <- fitted(predict_k5)
table(Actual=test$Species,fit)
install.packages("VIM")
library('VIM')
rm(list=ls())
library(rpart)
library(rpart.plot)  			# Enhanced tree plots
library(rattle)           # Fancy tree plot
library(RColorBrewer)     # colors needed for rattle
install.packages("rpart.plot")     # Enhanced tree plots
install.packages("rpart.plot")
install.packages("rpart")
install.packages("rpart.plot")     # Enhanced tree plots
install.packages("rattle")         # Fancy tree plot
install.packages("RColorBrewer")   # colors needed for rattle
library(rpart)
library(rpart.plot)  			# Enhanced tree plots
library(rattle)           # Fancy tree plot
library(RColorBrewer)     # colors needed for rattle
filename<-file.choose()
dsn<-  read.csv(filename )
set.seed(111)
?ifelse
index<-sort(sample(nrow(dsn),round(.25*nrow(dsn))))
training<-dsn[-index,]
test<-dsn[index,]
dev.off()
CART_class<-rpart( Survived~.,data=training)
rpart.plot(CART_class)
CART_predict2<-predict(CART_class,test, type="class")
table(Actual=test[,4],CART=CART_predict2)
CART_predict<-predict(CART_class,test)
CART_predict<-predict(CART_class,test)
str(CART_predict)
CART_predict_cat<-ifelse(CART_predict[,1]<=.5,'Yes','No')
table(Actual=test[,4],CART=CART_predict_cat)
CART_wrong<-sum(test[,4]!=CART_predict_cat)
CART_error_rate<-CART_wrong/length(test[,4])
CART_error_rate
CART_predict2<-predict(CART_class,test, type="class")
CART_wrong2<-sum(test[,4]!=CART_predict2)
CART_error_rate2<-CART_wrong2/length(test[,4])
CART_error_rate2
install.packages("C50")
rm(list=ls())
filename<-file.choose()
dsn<-  read.csv(filename )
dev.off
?na.omit()
dsn2<-na.omit(dsn)
set.seed(123)
?ifelse
index<-sort(sample(nrow(dsn),round(.25*nrow(dsn))))
training<-dsn[-index,]
test<-dsn[index,]
#install.packages("C50", repos="http://R-Forge.R-project.org")
#install.packages("C50")
library('C50')
C50_class <- C5.0( Survived~.,data=training )
summary(C50_class )
dev.off()
plot(C50_class)
C50_predict<-predict( C50_class ,test , type="class" )
table(actual=test[,4],C50=C50_predict)
wrong<- (test[,4]!=C50_predict)
c50_rate<-sum(wrong)/length(test[,4])
c50_rate
plot(C50_class)
install.packages("randomForest")
library(randomForest)
table(cancer$Class)
# CS 513 HW-2 EDA
# Name: Neil Gupte
# CWID:10445674
# purpose: hw 6 C5.0
rm(list=ls())
getwd()
dataset<-read.csv('breast-cancer-wisconsin.data.csv',na.string="?")
table(dataset$Class)
# CS 513 HW-2 EDA
# Name: Neil Gupte
# CWID:10445674
# purpose: hw 6 C5.0
rm(list=ls())
getwd()
dataset<-read.csv('breast-cancer-wisconsin.data.csv',na.string="?")
table(dataset$Class)
# CS 513 HW-2 EDA
# Name: Neil Gupte
# CWID:10445674
# purpose: hw 6 C5.0
rm(list=ls())
getwd()
dataset<-read.csv('breast-cancer-wisconsin.data.csv',na.string="?")
# CS 513 HW-2 EDA
# Name: Neil Gupte
# CWID:10445674
# purpose: hw 6 C5.0
rm(list=ls())
getwd()
dataset<-read.csv('breast-cancer-wisconsin.data.csv',na.string="?")
rm(list=ls())
getwd()
dataset<-read.csv('breast-cancer-wisconsin.csv',na.string="?")
setwd("C:/cs 513 HOMEWORK/hw6 c5 and randomfor")
# CS 513 HW-2 EDA
# Name: Neil Gupte
# CWID:10445674
# purpose: hw 6 C5.0
rm(list=ls())
getwd()
dataset<-read.csv('breast-cancer-wisconsin.data.csv',na.string="?")
table(dataset$Class)
# CS 513 HW-2 EDA
# Name: Neil Gupte
# CWID:10445674
# purpose: hw 6 C5.0
rm(list=ls())
getwd()
dataset<-read.csv('breast-cancer-wisconsin.data.csv',na.string="?")
table(dataset$Class)
dataset$Class <- factor(dataset$Class, levels = c(2,4),labels = c("Benign", "Malignant"))
# CS 513 HW-2 EDA
# Name: Neil Gupte
# CWID:10445674
# purpose: hw 6 C5.0
rm(list=ls())
getwd()
dataset<-read.csv('breast-cancer-wisconsin.data.csv',na.string="?")
table(dataset$Class)
dataset$Class <- factor(dataset$Class, levels = c(2,4),labels = c("Benign", "Malignant"))
idx<-sort(sample(nrow(dataset),as.integer(.70*nrow(dataset))))
training<-cancer[idx,]
test<-cancer[-idx,]
idx<-sort(sample(nrow(dataset),as.integer(.70*nrow(dataset))))
training<-dataset[idx,]
test<-dataset[-idx,]
model<-C5.0(Class~.,training[,-1])
summary(model)
library(C50)
# CS 513 HW-2 EDA
# Name: Neil Gupte
# CWID:10445674
# purpose: hw 6 C5.0
rm(list=ls())
getwd()
dataset<-read.csv('breast-cancer-wisconsin.data.csv',na.string="?")
table(dataset$Class)
dataset$Class <- factor(dataset$Class, levels = c(2,4),labels = c("Benign", "Malignant"))
idx<-sort(sample(nrow(dataset),as.integer(.70*nrow(dataset))))
training<-dataset[idx,]
test<-dataset[-idx,]
library(C50)
model<-C5.0(Class~.,training[,-1])
summary(model)
plot(model)
prediction<-predict(model,test[,-1],type="class")
conf_matrix<-table(test[,11],prediction)
conf_matrix
str(prediction)
wrong<-sum(test[,11]!=prediction)
error_rate<-wrong/length(test[,11])
error_rate
accuracy <- function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}
accuracy(confusionmatrix)
accuracy <- function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}
accuracy(conf_matrix)
# CS 513 HW-2 EDA
# Name: Neil Gupte
# CWID:10445674
# purpose: hw 6 C5.0
rm(list=ls())
getwd()
dataset<-read.csv('breast-cancer-wisconsin.data.csv',na.string="?")
table(dataset$Class)
dataset$Class <- factor(dataset$Class, levels = c(2,4),labels = c("Benign", "Malignant"))
idx<-sort(sample(nrow(dataset),as.integer(.70*nrow(dataset))))
training<-dataset[idx,]
test<-dataset[-idx,]
library(C50)
model<-C5.0(Class~.,training[,-1])
summary(model)
plot(model)
prediction<-predict(model,test[,-1],type="class")
#Forming the confusin matrix
conf_matrix<-table(test[,11],prediction)
conf_matrix
str(prediction)
#Showing the error rate
wrong<-sum(test[,11]!=prediction)
error_rate<-wrong/length(test[,11])
error_rate
accuracy <- function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}
accuracy(conf_matrix)
# CS 513 HW-2 EDA
# Name: Neil Gupte
# CWID:10445674
# purpose: hw 6 randomForest
rm(list=ls())
library(randomForest)
dataSet<-read.csv("breast-cancer-wisconsin.data.csv",na.strings = '?')
View(dataSet)
table(dataSet$Class)
#To factor the data set
dataSet$Class <- factor(dataSet$Class, levels = c(2,4),labels = c("Benign", "Malignant"))
dataSet<-na.omit(dataSet)
# To split the data set into test and testing
idx<-sort(sample(nrow(dataSet),as.integer(.70*nrow(dataSet))))
training<-dataSet[idx,]
test<-dataSet[-idx,]
fit <- randomForest( Class~., data=training, importance=TRUE, ntree=1000)
importance(fit)
varImpPlot(fit)
Prediction <- predict(fit, test)
table(actual=test$Class,Prediction)
wrong<- (test$Class!=Prediction )
errorRate<-sum(wrong)/length(wrong)
errorRate
errorRate<-sum(wrong)/length(wrong)
errorRate
# CS 513 HW-2 EDA
# Name: Neil Gupte
# CWID:10445674
# purpose: hw 6 randomForest
rm(list=ls())
library(randomForest)
dataSet<-read.csv("breast-cancer-wisconsin.data.csv",na.strings = '?')
View(dataSet)
table(dataSet$Class)
#To factor the data set
dataSet$Class <- factor(dataSet$Class, levels = c(2,4),labels = c("Benign", "Malignant"))
dataSet<-na.omit(dataSet)
# To split the data set into test and testing
idx<-sort(sample(nrow(dataSet),as.integer(.70*nrow(dataSet))))
training<-dataSet[idx,]
test<-dataSet[-idx,]
fit <- randomForest( Class~., data=training, importance=TRUE, ntree=1000)
importance(fit)
varImpPlot(fit)
Prediction <- predict(fit, test)
table(actual=test$Class,Prediction)
wrong<- (test$Class!=Prediction )
errorRate<-sum(wrong)/length(wrong)
errorRate
# CS 513 HW-2 EDA
# Name: Neil Gupte
# CWID:10445674
# purpose: hw 6 C5.0
rm(list=ls())
getwd()
dataset<-read.csv('breast-cancer-wisconsin.data.csv',na.string="?")
table(dataset$Class)
dataset$Class <- factor(dataset$Class, levels = c(2,4),labels = c("Benign", "Malignant"))
idx<-sort(sample(nrow(dataset),as.integer(.70*nrow(dataset))))
training<-dataset[idx,]
test<-dataset[-idx,]
library(C50)
model<-C5.0(Class~.,training[,-1])
summary(model)
plot(model)
prediction<-predict(model,test[,-1],type="class")
#Forming the confusin matrix
conf_matrix<-table(test[,11],prediction)
conf_matrix
str(prediction)
#Showing the error rate
wrong<-sum(test[,11]!=prediction)
error_rate<-wrong/length(test[,11])
error_rate
accuracy <- function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}
accuracy(conf_matrix)
install.packages("neuralnet")
#  Course          :CS 513 Data Mining
#  First Name      : Neil
#  Last Name       : Gupte
#  Id              : 10445674
#  purpose         : hw 7 ANN
rm(list=ls())
library(neuralnet)
dataSet<-read.csv("wisc_bc_ContinuousVar.csv",na.strings = '?')
View(dataSet)
table(dataSet$diagnosis)
setwd("C:/cs 513 HOMEWORK/hw7 ann")
#  Course          :CS 513 Data Mining
#  First Name      : Neil
#  Last Name       : Gupte
#  Id              : 10445674
#  purpose         : hw 7 ANN
rm(list=ls())
library(neuralnet)
dataSet<-read.csv("wisc_bc_ContinuousVar.csv",na.strings = '?')
View(dataSet)
table(dataSet$diagnosis)
rm(list=ls())
library(neuralnet)
dataSet<-read.csv("wisc_bc_ContinuousVar.csv",na.strings = '?')
View(dataSet)
table(dataSet$diagnosis)
rm(list=ls())
library(neuralnet)
dataSet<-read.csv("wisc_bc_ContinuousVar.csv",na.strings = '?')
View(dataSet)
table(dataSet$diagnosis)
#To factor the data set
dataSet<-data.frame(lapply(na.omit(dataSet),as.numeric))
# To split the data set into test and testing
idx<-sort(sample(nrow(dataSet),as.integer(.70*nrow(dataSet))))
training<-dataSet[idx,]
test<-dataSet[-idx,]
?neuralnet()
model<- neuralnet(diagnosis~.,training[-1], hidden=5, threshold=0.01)
#Plot the neural network
plot(model)
## test should have only the input colum
ann <-compute(model,test)
ann$net.result
ann_cat<-ifelse(ann$net.result <1.5,1,2)
length(ann_cat)
length(test$diagnosis)
table(ann_cat,test$diagnosis)
wrong<- (test$diagnosis!=ann_cat)
errorRate<-sum(wrong)/length(wrong)
rm(list=ls())
library(neuralnet)
dataSet<-read.csv("wisc_bc_ContinuousVar.csv",na.strings = '?')
View(dataSet)
table(dataSet$diagnosis)
#To factor the data set
dataSet<-data.frame(lapply(na.omit(dataSet),as.numeric))
# To split the data set into test and testing
idx<-sort(sample(nrow(dataSet),as.integer(.70*nrow(dataSet))))
training<-dataSet[idx,]
test<-dataSet[-idx,]
?neuralnet()
model<- neuralnet(diagnosis~.,training[-1], hidden=5, threshold=0.01)
#Plot the neural network
plot(model)
## test should have only the input colum
ann <-compute(model,test)
ann$net.result
ann_cat<-ifelse(ann$net.result <1.5,1,2)
length(ann_cat)
length(test$diagnosis)
table(ann_cat,test$diagnosis)
wrong<- (test$diagnosis!=ann_cat)
errorRate<-sum(wrong)/length(wrong)
rm(list=ls())
cancer<-read.csv("wisc_bc_ContinuousVar.csv",na.strings = '?')
View(cancer)
summary(cancer)
table(cancer$diagnosis)
cancer<-na.omit(cancer)
cancer<-cancer[-1]
cancer
cancer_dist<-dist(cancer[,-1])
hclust_results<-hclust(cancer_dist)
plot(hclust_results)
hclust_2<-cutree(hclust_results,2)
table(hclust_2,cancer[,1])
rm(list=ls())
cancer<-read.csv("wisc_bc_ContinuousVar.csv",na.strings = '?')
View(cancer)
summary(cancer)
table(cancer$diagnosis)
cancer<-na.omit(cancer)
cancer<-cancer[-1]
kmeans_2<- kmeans(cancer[,-1],2,nstart = 10)
kmeans_2$cluster
table(kmeans_2$cluster,cancer[,1])
